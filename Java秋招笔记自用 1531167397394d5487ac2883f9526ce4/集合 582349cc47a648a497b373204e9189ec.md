# 集合

![java-collection-hierarchy.png](%E9%9B%86%E5%90%88%20582349cc47a648a497b373204e9189ec/java-collection-hierarchy.png)

# List

## ArrayList

### ArrayList和Array的区别？

- ArrayList基于动态数组，可以动态扩容，Array是静态数组，创建之后不能改变长度；
- ArrayList可以使用泛型，Array不可以；
- ArrayList只能存储对象，Array可以直接存储基本数据类型；
- ArrayList创建时不需要指定大小（默认是10，扩容因子是1.5），Array创建时必须指定大小。

### ArrayList和Vector的区别？

- 两个底层都是Object[]；
- ArrayList是List的主要实现类，线程不安全；
- Vector是List的古老实现，线程安全。

### 时间复杂度分析？

- 头部插入：由于需要将所有元素都依次向后移动一个位置，因此时间复杂度是 O(n)。
- 尾部插入：当 `ArrayList` 的容量未达到极限时，往列表末尾插入元素的时间复杂度是 O(1)，因为它只需要在数组末尾添加一个元素即可；当容量已达到极限并且需要扩容时，则需要执行一次 O(n) 的操作将原数组复制到新的更大的数组中，然后再执行 O(1) 的操作添加元素。
- 指定位置插入：需要将目标位置之后的所有元素都向后移动一个位置，然后再把新元素放入指定位置。这个过程需要移动平均 n/2 个元素，因此时间复杂度为 O(n)。
- 头部删除：由于需要将所有元素依次向前移动一个位置，因此时间复杂度是 O(n)。
- 尾部删除：当删除的元素位于列表末尾时，时间复杂度为 O(1)。
- 指定位置删除：需要将目标元素之后的所有元素向前移动一个位置以填补被删除的空白位置，因此需要移动平均 n/2 个元素，时间复杂度为 O(n)。

## LinkedList

### 时间复杂度分析？

- 头部插入/删除：只需要修改头结点的指针即可完成插入/删除操作，因此时间复杂度为 O(1)。
- 尾部插入/删除：只需要修改尾结点的指针即可完成插入/删除操作，因此时间复杂度为 O(1)。
- 指定位置插入/删除：需要先移动到指定位置，再修改指定节点的指针完成插入/删除，因此需要遍历平均 n/2 个元素，时间复杂度为 O(n)。

### ArrayList和LinkedList区别？

- 底层数据结构：ArrayList底层是object数组，LinkedList底层是双向链表；
- 支持随机访问：`LinkedList` 不支持高效的随机元素访问，而 `ArrayList`（实现了 `RandomAccess` 接口） 支持；
- 插入和删除受元素位置的影响：`LinkedList` 采用链表存储，所以在头尾插入或者删除元素不受元素位置的影响；`ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。
- 内存空间占用：ArrayList的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。

# Set

### 比较HashSet、LinkedHashSet和TreeSet的区别？

- 都是 `Set` 接口的实现类，都能保证元素唯一，并且都不是线程安全的。
- `HashSet`、`LinkedHashSet` 和 `TreeSet` 的主要区别在于底层数据结构不同。`HashSet` 的底层数据结构是哈希表（基于 `HashMap` 实现）。`LinkedHashSet` 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。`TreeSet` 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。
- 底层数据结构不同又导致这三者的应用场景不同。`HashSet` 用于不需要保证元素插入和取出顺序的场景，`LinkedHashSet` 用于保证元素的插入和取出顺序满足 FIFO 的场景，`TreeSet` 用于支持对元素自定义排序规则的场景。

# Queue

### Deque和Queue的区别？

| `Queue` 接口 | 抛出异常 | 返回特殊值 |
| --- | --- | --- |
| 插入队尾 | add(E e) | offer(E e) |
| 删除队首 | remove() | poll() |
| 查询队首元素 | element() | peek() |

| `Deque` 接口 | 抛出异常 | 返回特殊值 |
| --- | --- | --- |
| 插入队首 | addFirst(E e) | offerFirst(E e) |
| 插入队尾 | addLast(E e) | offerLast(E e) |
| 删除队首 | removeFirst() | pollFirst() |
| 删除队尾 | removeLast() | pollLast() |
| 查询队首元素 | getFirst() | peekFirst() |
| 查询队尾元素 | getLast() | peekLast() |

### ArrayDeque 与 LinkedList 的区别？

都实现了Deque接口：

- `ArrayDeque` 是基于可变长的数组和双指针来实现，而 `LinkedList` 则通过链表来实现。
- `ArrayDeque` 不支持存储 `NULL` 数据，但 `LinkedList` 支持。
- `ArrayDeque` 插入时可能存在扩容过程， 不过均摊后的插入操作依然为 O(1)。虽然 `LinkedList` 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。

# Map

### Map接口有哪些实现，该怎么选择？

Map接口有很多实现类，其中比较常用的有HashMap、LinkedHashMap、TreeMap、ConcurrentHashMap。

- 对于不需要排序的场景，优先考虑使用HashMap，因为它是性能最好的Map实现。如果需要保证线程安全，则可以使用ConcurrentHashMap。它的性能好于Hashtable，因为它在put时采用分段锁/CAS的加锁机制，⽽不是像Hashtable那样，无论是put还是get都做同步处理。
- 对于需要排序的场景，如果需要按插⼊顺序排序则可以使用LinkedHashMap，如果需要将key按自然顺序排列甚至是自定义顺序排列，则可以选择TreeMap。如果需要保证线程安全，则可以使用Collections工具类将上述实现类包装成线程安全的Map。

### HashMap和HashTable的区别？

- 线程安全和性能：
    - HashTable是线程安全的，通过在方法上添加Synchronized关键字实现，但可能导致性能下降。
    - HashMap在多线程环境下不是线程安全的，在单线程环境下性能比HashTable好，因为没有同步开销。
- HashMap可以使用null作为key和value（key只能有一个null，value可以有多个），但HashTable不允许。
- HashMap是AbstractMap的子类，实现了Map接口，HashTable是Dictionary类的子类。
- HashMap默认的大小是16，每次扩容变为2倍，HashTable默认的大小是11，每次扩容变为2n+1。如果给定了容量初始值，那么 `Hashtable` 会直接使用你给定的大小，而 `HashMap` 会将其扩充为 2 的幂次方大小。

### 为什么HashMap的初始化容量是2的n次幂？

1. 一般通过%求余来确定位置，但是性能不如&运算，当容量是2的幂次方时，hash & (length -1) == hash % length，达到和取余同样的效果，使数据均匀分布，减少hash冲突。
2. 如果创建的对象输入长度不是2次幂，HashMap会通过操作（>>> and |）得到比输入值大的最小的2次幂的数作为初始化容量。

### HashMap的原理及扩容机制？

HashMap 通过 key 的hashcode经过扰动函数处理过后得到 hash 值，然后通过(n - 1) & hash判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。jdk1.7以前采用头插法，jdk1.8以后采用尾插法。jdk1.8以后，当链表长度大于阈值（默认8）、数组长度大于64时 ，将链表转化为红黑，提高查询的效率。当红黑树节点小于6会退化成链表。

### 为什么HashMap转红黑树的阈值是8？

因为根据泊松分布，hash碰撞八次发生的概率已经几乎为不可能事件了，如果小概率事件发生了，说明由于元素本身或哈希函数的原因，后续hash碰撞的可能性会非常大，因此，该将链表转换为红黑树了。

### HashMap的put方法原理？

1. 判断table是否为空，如果为空则进行一次扩容；
2. 计算hash值得到数组索引；
3. 判断哈希表对应索引位是否为空：
    1. 如果为空则直接插入；
    2. 如果不为空，判断key是否存在：
        1. 如果存在，直接覆盖value；
        2. 如果不存在，则插入键值对。如果是链表，还要先判断链表长度是否大于8，大于8需要转换红黑树。
4. 计算当前的K-V数量，如果大于临界值进行扩容$threshold=capacity \times loadFactor$，装载因子默认为0.75。

### 遍历HashMap的方式有哪些？

1. 分别遍历Key和Value；
    
    ```java
    Set<String> keys = map.keySet();
    Collection<Integer> values = map.values();
    ```
    
2. 迭代器
    
    ```java
    Set<Map.Entry<String, Integer>> entries = map.entrySet();
    for(Iterator<Map.Entry<String, Integer>> it = entries.iterator(); it.hasNext(); ){
    		Map.Entry<String, Integer> entry = it.next();
    		entry.getKey();
    		entry.getValue();
    }
    ```
    
3. 通过get()（不建议）
    
    ```java
    Set<String> keys = map.keySet();
    for(String s: keys) {
    		map.get(s);
    }
    ```
    
4. map接口中的forEach
    
    ```java
    map.forEach((k, v)-> {...});
    ```
    

### HashMap为什么会有线程安全问题？

JDK1.7 及之前版本的 `HashMap` 在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。

为了解决这个问题，JDK1.8 版本的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 `HashMap`，因为多线程下使用 `HashMap` 还是会存在数据覆盖的问题。并发环境下，推荐使用 `ConcurrentHashMap` 。

### ConcurrentHashMap和HashTable的区别？

- **底层数据结构：** JDK1.7 的 `ConcurrentHashMap` 底层采用 **分段的数组+链表** 实现，JDK1.8 采用的数据结构跟 `HashMap1.8` 的结构一样，数组+链表/红黑二叉树。`Hashtable` 和 JDK1.8 之前的 `HashMap` 的底层数据结构类似都是采用 **数组+链表** 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；
- **实现线程安全的方式（重要）：**
    - 在 JDK1.7 的时候，`ConcurrentHashMap` 对整个桶数组进行了分割分段(`Segment`，分段锁)，每一把锁只锁容器其中一部分数据（下面有示意图），多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。
    - 到了 JDK1.8 的时候，`ConcurrentHashMap` 已经摒弃了 `Segment` 的概念，而是直接用 `Node` 数组+链表+红黑树的数据结构来实现，并发控制使用 `synchronized` 和 CAS 来操作。（JDK1.6 以后 `synchronized` 锁做了很多优化） 整个看起来就像是优化过且线程安全的 `HashMap`，虽然在 JDK1.8 中还能看到 `Segment` 的数据结构，但是已经简化了属性，只是为了兼容旧版本；
    - **`Hashtable`(同一把锁)** :使用 `synchronized` 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

### ConcurrentHashMap的实现原理？

1. jdk1.8之前：
    
    ![java7_concurrenthashmap.png](%E9%9B%86%E5%90%88%20582349cc47a648a497b373204e9189ec/java7_concurrenthashmap.png)
    
    **`ConcurrentHashMap` 是由 `Segment` 数组结构和 `HashEntry` 数组结构组成**。首先将数据分为一段一段（这个“段”就是 `Segment`）的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。`Segment` 继承了 `ReentrantLock`,所以 `Segment` 是一种可重入锁，扮演锁的角色。`Segment` 的个数一旦**初始化就不能改变**。 `Segment` 数组的大小默认是 16，也就是说默认可以同时支持 16 个线程并发写。
    
2. jdk1.8之后：
    
    ![java8_concurrenthashmap.png](%E9%9B%86%E5%90%88%20582349cc47a648a497b373204e9189ec/java8_concurrenthashmap.png)
    
    ConcurrentHashMap取消了Segment分段锁，采用Node + CAS + synchronized来保证并发安全。数据结构跟HashMap1.8 的结构类似，数组+链表/红黑二叉树。Java 8 中，锁粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。
    

### 1.7和1.8版本ConcurrentHashMap的区别？

- **线程安全实现方式**：JDK 1.7 采用 `Segment` 分段锁来保证安全， `Segment` 是继承自 `ReentrantLock`。JDK1.8 放弃了 `Segment` 分段锁的设计，采用 `Node + CAS + synchronized` 保证线程安全，锁粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点。
- **Hash 碰撞解决方法** : JDK 1.7 采用拉链法，JDK1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。
- **并发度**：JDK 1.7 最大并发度是 Segment 的个数，默认是 16。JDK 1.8 最大并发度是 Node 数组的大小，并发度更大。