# 并发

# Java线程

## 与进程的区别

- 进程是资源分配的基本单位，线程是系统调度的基本单位。
- 一个进程包含多个线程，线程共享进程的内存空间和系统资源。

## 创建线程的方式

1. **继承`Thread`类，重写`run`方法。**调用`start`方法开启线程。
2. **实现`Runable`接口，重写`run`方法。**用`Thread`类包装`FutureTask` 对象，调用`start`方法开启线程。
3. **实现`Callable`接口，重写`call`方法。**
    1. 用`FutureTask`类包装`Callable`对象。`FutureTask`实现了`Runable`接口并在`run`方法中调用`call`方法。
    2. 用`Thread`类包装`FutureTask` 对象，调用`start`方法开启线程。
    3. 调用`FutureTask`的`get`方法获取线程执行结束的返回值。
4. **创建线程池。**
- run方法和start方法的区别：
    - run方法是线程的执行体，直接调用run方法会在当前线程上下文中执行，不会创建新线程。
    - start方法会启动新线程并使线程进入就绪状态，在新线程中执行run方法代码。

## Java线程状态

![Untitled](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/Untitled.png)

- Java将就绪和运行统称为Runable状态，切换太快没必要区分。
- Java将阻塞分为：
    - 阻塞
    - 等待
    - 超时等待
1. sleep()与wait()方法的区别？
    1. `sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁 ，并将线程加入等待队列中。
    2. `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
    3. `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒。
    4. `sleep()` 是 `Thread` 类的静态本地方法，`wait()` 则是 `Object` 类的本地方法。
2. wait()为什么定义在Object中？
    
    应为wait()是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。 `sleep()` 是让当前线程暂停执行，也不涉及对象。
    
3. yield()将线程置为就绪状态，但保留cpu的执行资格。与sleep一样都是定义在Thread类里的静态方法。
4. join()将线程置为阻塞状态，等待join()线程执行完再执行。

![Untitled](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/Untitled%201.png)

# 多线程

## 并发与并行

- **并发**：两个及两个以上的作业在同一 **时间段** 内执行。
- **并行**：两个及两个以上的作业在同一 **时刻** 执行。

## 同步与异步

- **同步**：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。
- **异步**：调用在发出之后，不用等待返回结果，该调用直接返回

## 上下文切换

由于线程的CPU时间片用完、线程调用sleep/yield等方法、垃圾回收等原因，CPU不再执行当前的线程，执行另一个线程。需要保存当前线程的状态，并恢复另一个线程的状态。上下文的切换会有时间开销。

## 多线程的问题

1. 线程安全：多个线程对共享资源的访问不会导致数据的不一致性（原子性和可见性）
2. 活跃性：死锁、饥饿（低优先级的线程迟迟不能运行）
3. 性能问题：创建线程和线程上下文切换会有开销

# 并发编程特性

## 原子性

一次或多次操作要么都执行，要么都不执行。

`synchronized` 和`Lock` 解决。`volatile`不能保证原子性。

## 可见性

一个线程运行的结果可以被其他线程看到。

内存模型：Java线程中的通信采用共享内存模型，每个线程有自己的工作内存（缓存Cache、寄存器等一系列的抽象）（CPU处理快，去内存读数据太慢了）。主内存对应JVM中的线程共享区，线程工作时将需要的数据拷贝到工作内存中，从工作内存中读数据处理，将处理完的数据写回到主内存中。

---

`volatile`的底层原理：通过汇编lock前缀指令锁定缓存，写回主内存。lock指令的作用：

1. 将处理器缓存行的数据立即写到系统内存。
2. 引起其他CPU里缓存了改内存地址的数据无效（MESI原则）。
    
    > 缓存一致性原则（MESI）：多个cpu从主内存读取同一个数据到各自的高速缓存，当其中某个cpu修改了缓存里的数据，该数据会马上同步回主内存，其它cpu通过总线嗅探机制可以感知到数据的变化从而将自己缓存里的数据失效。
    > 
3. 提供内存屏障功能，前后指令不能重排。

---

`synchronized`获取锁资源之后，将内部涉及到的变量从CPU缓存中移除，必须去主内存中重新拿数据，而且在释放锁之后，会立即将CPU缓存中的数据同步到主内存。

---

`final`不允许被修改，保证了可见性，不能与volatile一起使用。

## 有序性

有序性指的是程序能够按照代码的顺序来执行。

编译器为了提高运行效率，从源代码到执行的最终指令进行了三次重排：编译器优化重排序（语句执行顺序）、指令级并行重排序（机器执行指令的顺序）、内存系统重排序（使用缓存和读写缓冲，导致加载和存储像在乱序执行）。

重排序遵循的两个原则：

- as-if-serial：重排序不影响单线程程序最后的结果。
- happens-before：（1）前面一个操作的结果对之后操作是可见的，（2）两个操作即使存在happens-before关系，也不意味着Java平台的具体实现要按指定的顺序。规定了八种规则，例如：
    - 对同一个锁的解锁要在后续加锁之前；
    - 线程启动操作要在这个线程第一个操作之前；
    - ……

`volatile`防止指令重排。

# 线程锁

## 锁的种类

### 可重入锁

**可重入锁**也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。

### 公平锁与非公平锁

- **公平锁** : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。
- **非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。

### 可中断锁和不可中断锁

- **可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后才能进行其他逻辑处理。
- **不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。

### 共享锁（S锁）和独占锁（X锁）

- **共享锁**：一把锁可以被多个线程同时获得。
- **独占锁**：一把锁只能被一个线程获得。

### 乐观锁与悲观锁

乐观锁与悲观锁是看待并发的角度：

- 悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。
- 乐观锁假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了。

在高并发场景下，悲观锁可能导致激烈的锁竞争，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。并且，悲观锁还可能会存在死锁问题，影响代码的正常运行。乐观锁如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试，这样同样会非常影响性能，导致 CPU 飙升。

- 悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如`LongAdder`），也是可以考虑使用乐观锁的，要视实际情况而定。
- 乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考`java.util.concurrent.atomic`包下面的原子变量类）。

**CAS（Compare And Swap）算法实现乐观锁？**

CAS 涉及到三个操作数：

- **V**：要更新的变量值(Var)
- **E**：预期值(Expected)
- **N**：拟写入的新值(New)

当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。

CAS的问题：

- ABA问题：值被其他线程改过之后又被改回来，添加时间戳或版本号解决。
- 循环时间开销大：CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功，长时间不成功会给CPU带来很大开销。
- 只能保证一个共享变量的原子操作。

## AQS

![clh-queue-state.png](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/clh-queue-state.png)

核心思想：

- 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。
- 如果被请求的共享资源被占用，则将活不到锁的线程加入到队列中，阻塞等待唤醒。

AQS`AbstractQueuedSynchronizer`总的来说就是一个操作node队列和控制state状态的过程，以此来实现多个线程的同步。

- AQS通过被`volatile`修饰的成员变量`state`表示资源获锁的情况。
- Node节点属性包括节点的属性（prev/next/thread/head/tail）、mode（Shared/Exclusive）和waitStatus。
    - 0：Node被初始化的默认值；
    - CANCELLED：1，获锁的请求已取消；
    - CONDITION：-2，节点在等待队列中，等待唤醒；
    - PROPAGATE：-3，在shared情况下使用；
    - SIGNAL：-1，线程已准备好，等待资源释放。
- 自定义同步器时需要实现以下方法：

```java
//独占方式。尝试获取资源，成功则返回true，失败则返回false。
protected boolean tryAcquire(int)
//独占方式。尝试释放资源，成功则返回true，失败则返回false。
protected boolean tryRelease(int)
//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
protected int tryAcquireShared(int)
//共享方式。尝试释放资源，成功则返回true，失败则返回false。
protected boolean tryReleaseShared(int)
//该线程是否正在独占资源。只有用到condition才需要去实现它。
protected boolean isHeldExclusively()
```

## Java中的锁

### synchronized

保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行，可重入且独占式的锁。

```java
// 修饰代码块，锁住类(.class)或对象
synchronized(this) {}
// 修饰实例方法，锁住实例
synchronized void method() {}
// 修饰静态方法，锁住类
synchronized static void method() {}
```

- 构造方法不能使用 `synchronized`关键字修饰。不过，可以在构造方法内部使用 `synchronized` 代码块。
- `synchronized`和`volatile`的区别：
    - `volatile` 关键字是线程同步的轻量级实现，性能比`synchronized`关键字要好。
    - `volatile` 关键字只能用于变量而 `synchronized` 关键字可以修饰方法以及代码块 。
    - `volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。

**synchronied锁升级**

![Untitled](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/Untitled%202.png)

对象头由`Mark Word`和`Klass Word`组成，其中，Mark Word记录了锁状态。synchronized锁有四种状态：无锁、偏向锁、轻量级锁、重量级锁。

1. 偏向锁（后续版本删除）：当一个线程首次获得锁时，将标记为偏向锁，避免未来获得锁或释放锁的开销。
    
    原理：一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID。当下次该线程进入这个同步块时，会去检查锁的 Mark Word 里面是不是放的自己的线程 ID。
    
    ![synchronized-20230728112620.png](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/synchronized-20230728112620.png)
    
    - 为什么撤销偏向锁：偏向锁升级为轻量级锁开销很大，例如，停止拥有锁的线程，修复锁记录和Mark Word，唤醒被停止的线程，所以，如果程序里的锁经常处于竞争状态，偏向锁会成为一种累赘。
2. 轻量级锁：如果另一个线程尝试获取已被偏向的锁，偏向锁会升级为轻量级锁。（多线程访问的时间是错开的，没有竞争关系）
    
    原理：线程的栈帧中存放锁记录，记录锁记录的地址和锁住的对象，加锁时将对象头Mark Word和锁地址交换，解锁时再换回来。
    
    - 交换成功：加锁成功。
    - 交换失败，会自旋：
        - 如果占有的线程是其他线程，进入锁膨胀，升级为重量级锁。
        - 如果占有的线程是自己，即锁重入，再添加一条所记录作为计数。
    
    ![Untitled](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/Untitled%203.png)
    
3. 重量级锁：在加轻量级锁的过程中，如果有线程之间的竞争，则升级为重量级锁。
    
    锁膨胀的过程：
    
    - Object对象申请Monitor锁；
    - 线程进入Monitor对象的EntryList中阻塞。
    
    ![Untitled](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/Untitled%204.png)
    
    重量级锁竞争的时候通过自旋锁优化，避免阻塞造成的上下文切换开销。
    

### ReentrantLock

`ReentrantLock` 实现了 `Lock` 接口，是一个可重入且独占式的锁，比`synchronized` 更灵活、强大。默认使用[非公平锁](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953.md)，可以在构造函数上指定。

```java
Lock lock = new ReentrantLock();
try {
	lock.lock();
	// ...业务操作
}
finally {
	lock.unlock();
}
```

- `synchronized`和`reentrantLock`的比较：
    - 都是可重入锁；
    - `synchronized` 的实现依赖于JVM，在JVM层做了很多优化，`reentrantLock` 在JDK层面优化，需要配合lock、unlock、try…catch来完成。
    - `reentrantLock` 实现了公平锁和非公平锁，而`synchronized` 是非公平锁。
    - `reentrantLock` 是可中断锁，`synchronized` 是不可中断锁。
- 一般用在高并发情况下，高并发`synchronized` 性能降得比较多。

原理：基于AQS实现

非公平锁，使用AQS实现非公平同步器：

![RECTIFY_IMG_20240603_230958_1717427533496.jpg](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/RECTIFY_IMG_20240603_230958_1717427533496.jpg)

![RECTIFY_IMG_20240603_231137.jpg](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/RECTIFY_IMG_20240603_231137.jpg)

### Semaphore

允许多个线程访问某个资源，通常用于那些资源有明确访问数量限制的场景比如限流。支持公平/非公平方式。

```java
// 初始共享资源数量
final Semaphore semaphore = new Semaphore(5);
// 获取1个许可
semaphore.acquire();
// 释放1个许可
semaphore.release();
```

### Atomic

i++包括读、改、写三个步骤，不是原子的，两个线程共同执行100次i++，得到的数范围在2~200之间。用AtomicInteger类可以将类似操作变成原子的，不需要使用synchronized将操作变成原子操作。

# 线程池

## 基本概念

1. 什么是线程池？
    
    线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。
    
2. 线程池的好处？
    - **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    - **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
    - **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

## 创建线程池

```java
public class ThreadPoolExample {
    public static void main(String[] args) {
        int corePoolSize = 5;
        int maximumPoolSize = 10;
        long keepAliveTime = 60l;
        BlockingQueue<Runnable> workQueue = new ArrayBlockingQueue<>(10);

        ThreadPoolExecutor exec = new ThreadPoolExecutor(
                corePoolSize,
                maximumPoolSize,
                keepAliveTime,
                TimeUnit.SECONDS,
                workQueue,
                new ThreadPoolExecutor.CallerRunsPolicy()
        );
        for (int i = 0; i < 10; i++) {
            exec.submit(() -> {
                System.out.println(Thread.currentThread().getName());
            });
        }
        exec.shutdown();
    }
}
```

1. 通过`ThreadPoolExecutor`构造函数来创建。
    
    ⭐核心参数：
    
    - `int corePoolSize` // 线程池的核心线程数量
    - `int maximumPoolSize`  // 最大线程数
    - `long keepAliveTime` // 超过核心线程的空闲线程存活最长时间
    - `TimeUnit unit` // 时间单位
    - `BlockingQueue<Runnable> workQueue` // 任务队列
    - `ThreadFactory threadFactory` // 线程工厂，创建线程，一般默认
    - `RejectedExecutionHandler handler`  // 拒绝策略
2. 如何给线程池命名？
    1. 通过guava的`ThreadFactoryBuilder` 
        
        ```java
        ThreadFactory threadFactory = new ThreadFactoryBuilder()
                                .setNameFormat(threadNamePrefix + "-%d")
                                .setDaemon(true).build();
        ExecutorService threadPool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.MINUTES, workQueue, threadFactory);
        ```
        
    2. 自己实现`ThreadFactory` 
3. 核心线程数怎么确定？
    
    线程数太少导致任务积压，线程设置太大导致频繁的上下文切换。
    
    - **CPU 密集型任务(N+1)：** 这种任务（计算、加密、解密……）消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。
    - **I/O 密集型任务(2N)：** 这种任务（IO读写、网络通信、数据库读写……）应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

## 关闭线程池

关闭线程池可以用shutdown或shutdownNow。

- shutdown()会将线程池状态设置为shutdown，然后中断所有没有正在执行任务的线程。
- shutdownNow()会将线程池状态设置为stop，然后停止所有正在执行或暂停任务的线程。

## 任务提交

通过excute()和submit()提交任务。

- excute()提交不需要返回值的任务；
- submit()提交需要返回值的任务，会返回一个future对象，通过get方法可以获取返回值。

## 运行原理

![thread-pool-principle.png](%E5%B9%B6%E5%8F%91%205c8419960fe84625967557cec34e2953/thread-pool-principle.png)

注意：懒加载，没达到最大核心线程数不管有没有空闲线程都会创建新的，什么时候要用线程什么时候再加载，因为创建线程要消耗时间。

## 拒绝策略

1. 什么时候拒绝？
    - 调用shutdown关闭线程池后再提交任务。
    - 线程达到最大线程数且无空闲、阻塞队列也满了。
2. 拒绝策略有哪些？
    1. `ThreadPoolExecutor.AbortPolicy`：（默认）直接抛出异常，程序终止。
    2. `ThreadPoolExecutor.DiscardPolicy`：不处理直接丢弃。
    3. `ThreadPoolExecutor.DiscardOldestPolicy`：丢弃最早未处理的请求。
    4. `ThreadPoolExecutor.CallerRunsPolicy`：将任务交给提交任务的线程执行。子线程→主线程
    5. 自定义。
3. `CallerRunsPolicy` 的风险？
    
    如果提交任务的线程是主线程，且任务耗时，则可能阻塞主线程。
    
    - 提高最大线程数或阻塞队列大小；
    - 将任务持久化，放在缓存、消息队列或者数据库中；
    - 创建线程池以外的线程处理。

## 阻塞队列

BlockingQueue（阻塞队列）是一个接口，继承自Queue。BlockingQueue阻塞的原因是其支持当队列没有元素时一直阻塞，直到有元素；还支持如果队列已满，一直等到队列可以放入新元素时再放入。

1. 常见的阻塞队列？
    1. `LinkedBlockingQueue` 是一个由链表结构支持的可选有界（默认为无界）队列。
    2. `ArrayBlockingQueue` 是一个由数组支持的有界阻塞队列。这个队列按 FIFO（先进先出）原则对元素进行排序。
    3. `PriorityBlockingQueue` 是一个支持优先级排序的无界阻塞队列。队列中元素的排序可以根据自然排序，或者根据构造时提供的 `Comparator` 来进行。
    4. `SynchronousQueue` 是一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，反之亦然。如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。最大线程数无限拓展，容易OOM。
2. `ArrayBlockingQueue` 和`LinkedBlockingQueue` 的区别？
    - 底层实现：`ArrayBlockingQueue` 基于数组实现，而 `LinkedBlockingQueue` 基于链表实现。
    - 是否有界：`ArrayBlockingQueue` 是有界队列，必须在创建时指定容量大小。`LinkedBlockingQueue` 创建时可以不指定容量大小，默认是`Integer.MAX_VALUE`，也就是无界的。但也可以指定队列大小，从而成为有界的。
    - 锁是否分离： `ArrayBlockingQueue`中的锁是没有分离的，即生产和消费用的是同一个锁；`LinkedBlockingQueue`中的锁是分离的，即生产用的是`putLock`，消费是`takeLock`，这样可以防止生产者和消费者线程之间的锁争夺。
    - 内存占用：`ArrayBlockingQueue` 需要提前分配数组内存，而 `LinkedBlockingQueue` 则是动态分配链表节点内存。这意味着，`ArrayBlockingQueue` 在创建时就会占用一定的内存空间，且往往申请的内存比实际所用的内存更大，而`LinkedBlockingQueue` 则是根据元素的增加而逐渐占用内存空间。
3. 为什么使用阻塞队列？
    1. 创建救急线程会影响效率；
    2. 自动阻塞和唤醒线程。

## 线程异常

线程池中线程异常是删除还是复用？

- **使用`execute()`提交任务**：当任务通过`execute()`提交到线程池并在执行过程中抛出异常时，如果这个异常没有在任务内被捕获，那么该异常会导致当前线程终止，并且异常会被打印到控制台或日志文件中。线程池会检测到这种线程终止，并创建一个新线程来替换它，从而保持配置的线程数不变。
- **使用`submit()`提交任务**：对于通过`submit()`提交的任务，如果在任务执行中发生异常，这个异常不会直接打印出来。相反，异常会被封装在由`submit()`返回的`Future`对象中。当调用`Future.get()`方法时，可以捕获到一个`ExecutionException`。在这种情况下，线程不会因为异常而终止，它会继续存在于线程池中，准备执行后续的任务。

## Executor框架

### 组成

1. 任务：Runable接口和Callable接口。
2. 执行：Excutor接口以及继承自Excutor接口的ExcutorService。由两个关键的类实现了ExcutorService，即ThreadPoolExcutor（执行被提交的任务）和ScheduledThreadPoolExcutor（用于延时执行或定期执行）。
3. 异步结果：Future接口和实现该接口的FutureTask（代表异步计算的结果）。

执行过程：

1. 主线程创建实现Runnable和callable接口的任务对象。工具类Executors可以将Runnable封装成Callable对象。
2. 将任务对象交给Executor执行：
    1. 有返回值：ExcutorService.submit(callable<T> task)和ExcutorService.submit(Runnable task)；
    2. 无返回值：ExcutorService.execute(Runnable task)。
3. 返回FutureTask对象，主线程通过get()等待任务完成，也可以取消任务。

### ThreadPoolExecutor

Executor框架种的工具类Executors可以创建3种类型的ThreadPoolExecutor。

1. FixedThreadPool：可重用固定线程数的线程池，限制了线程数，适合负载比较重的场景；
    1. 核心线程数和最大线程数相同；
    2. 使用无界队列LinkedBlockingQueue（最大容量Integer.MAX_VALUE）（不会拒绝任务）。
2. SingleThreadExecutor：使用单个线程的执行器，适用于需要保证顺序执行任务的场景；
    1. 核心线程数和最大线程数相同，且为1；
    2. 使用无界队列LinkedBlockingQueue（最大容量Integer.MAX_VALUE）（不会拒绝任务）。
3. CachedThreadPool：根据需要创建新线程的线程池，适合短期异步任务的小程序或负载较轻的服务器；
    1. 核心线程为0，最大线程数为Integer.MAX_VALUE；
    2. 最大存活时间为60秒；
    3. 使用没有容量的SynchronousQueue作为工作队列。

### Future接口

```java
// V 代表了Future执行的任务返回值的类型
public interface Future<V> {
    // 取消任务执行
    // 成功取消返回 true，否则返回 false
    boolean cancel(boolean mayInterruptIfRunning);
    // 判断任务是否被取消
    boolean isCancelled();
    // 判断任务是否已经执行完成
    boolean isDone();
    // 获取任务执行结果
    V get() throws InterruptedException, ExecutionException;
    // 指定时间内没有返回计算结果就抛出 TimeOutException 异常
    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutExceptio
}
```

将任务交给Future，可以取消任务、查看任务的执行状态获取任务的执行结果。FutureTask就是对接口的实现，接受callable或runable对象。