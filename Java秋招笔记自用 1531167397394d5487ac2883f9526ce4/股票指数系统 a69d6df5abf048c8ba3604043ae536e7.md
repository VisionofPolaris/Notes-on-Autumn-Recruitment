# 股票指数系统

# 项目基础

## 项目介绍

该项目是基于股票交易实时数据产生的**数据分析产品**，项目旨在为用户和机构提供股票数据分析和展示服务，项目是前后端分离的架构，后端在技术上主要包括：

- 数据层的MySQL、Redis、Caffine Cache等；
- 应用层的Spring、SpringMVC、SpringBoot等。

在业务上主要包括两个模块：

- 数据采集：定时获取股票的数据并入库；
- 数据的分析与展示：主要功能包括A股大盘指数、板块指数展示、个股涨幅、K线行情等等。

## 项目架构

![1672834599561.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1672834599561.png)

采用前后端分离架构，主要使用的后端技术包括：

- **数据层**：MySQL、Redis等。
- **应用层**：
    - Spring、SpringMVC、SpringBoot基础框架；
    - SpringSecuriy+JWT安全框架负责认证和授权；
    - Sharding-JDBC实现分库分表方案的落地；
    - Xxl-job定时采集股票数据等。

后端工程主要包括四个模块：[多个Maven模块的聚合？](Maven%20bb4fe7ee738644c4852de59bac6d062e.md) 

![1656421735692.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1656421735692.png)

- 一个父工程：聚合子工程，导入公共的依赖资源、统一管理资源依赖的版本；
- 三个子工程：
    - common工程是对主业务共性的代码进行抽取，如pojo、utils、mapper等；
    - backend工程用于股票数据的分析展示；
    - job工程负责股票数据的采集。

## 项目功能

1. 数据展示：
    1. 国内大盘指数功能：获取最新的国内A股大盘数据，包含上证和深证大盘数据。A股大盘的开盘周期是周一至周五，每天上午9:30~11:30和下午1:00~3:00。
    2. 板块指数功能：获取最新的板块交易指数（电子信息、生物制药、机械行业等）。
    3. 股票K线图功能：（1）查询个股的分时行情数据，即统计指定股票T日每分钟的交易数据。（2）查询个股的日K线数据，即每天产生的数据（最高、最低、开盘、收盘价等）。
2. 数据统计分析：
    1. 个股的涨幅和振幅统计：计算个股的涨幅和振幅，并按照涨幅降序输出。基于PageHelper进行分页，并将数据返回。
    2. 涨跌停数据统计：A股市场有±10%的限制，统计每个时间段下涨幅查出限制的个股数目。实际上，是否涨跌停由证券交易所来确定，可能会超过10%或低于-10%，其实不应由我们统计决定。
    3. 股票成交量对比：统计A股大盘T日和T-1日成交量（沪深两市成交量之和）对比。
    4. 个股分时涨跌幅度统计：统计当前时间下（精确到分钟），A股在各个涨跌区间股票的数量。股票涨跌幅区间定义: "<-7%" 、 "-7~-5%"、 "-5~-3%" 、 "-3~0%" 、"0~3%" 、 "3~5%" 、 "5~7%" 、 ">7%”。

# 数据表

## 股票相关的表

![1662082285273.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1662082285273.png)

![1662082435249.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1662082435249.png)

- 大盘指数：由证券交易所经过一系列专业计算得出的一个反应股市行情健康状态的指数，A股大盘由上交所和深交所提供。
- 板块指数：板块指数可以更加细粒度的反应具体某个行业股市的活跃程度。

## 用户权限表

![1662082685953.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1662082685953.png)

![1657504077986.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1657504077986.png)

## 日志表

![1662082786986.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1662082786986.png)

## 数据表的查询优化

在A股数据涨幅榜中，需要统计A股股票涨幅的最新数据，根据涨幅排序取前五个股票信息返回。通常的做法是查询所有的数据，按照时间和涨幅进行降序，取前五个信息。这样的做法会导致全表查询开销大。

```sql
select 
	sri.trade_amount as tradeAmt,
	sri.pre_close_price as preClosePrice,
	(sri.max_price- sri.min_price)/sri.pre_close_price as amplitude,
	sri.stock_code as code,
	sri.stock_name as name,
	sri.cur_time   as curDate,
	sri.trade_volume as tradeVol,
	(sri.cur_price-sri.pre_close_price) as upDown,
	(sri.cur_price- sri.pre_close_price)/sri.pre_close_price as increase,
	sri.cur_price as tradePrice
from stock_rt_info as sri 
order by sri.cur_time desc,upDown desc
```

改进方法是先根据交易时间走索引查询，再根据查到的数据按照涨幅排序。

```sql
select 
	sri.trade_amount as tradeAmt,
	sri.pre_close_price as preClosePrice,
	(sri.max_price- sri.min_price)/sri.pre_close_price as amplitude,
	sri.stock_code as code,
	sri.stock_name as name,
	sri.cur_time   as curDate,
	sri.trade_volume as tradeVol,
	(sri.cur_price-sri.pre_close_price) as upDown,
	(sri.cur_price- sri.pre_close_price)/sri.pre_close_price as increase,
	sri.cur_price as tradePrice
from stock_rt_info as sri 
where sri.cur_time='2021-12-30 09:42:00'
order by upDown desc
```

# 技术1：Redis模拟session机制

## 描述

使用redis模拟session机制，实现验证码的生成和校验功能。

## 问题

### 什么是cookie和session？

Cookie 和 Session 是 Web 开发中用于管理用户会话（session）的两种主要机制，它们帮助网站记住用户的信息或状态。Cookie 是一种存储在用户本地终端上的数据，而Session 是一种服务器端存储机制，依赖于客户端发送的会话ID来识别用户会话，相对于Cookie，存储的数据量更大，安全性更高，但可能会消耗更多的资源。

### 为什么要用redis模拟？

前后端分离架构由于浏览器的同源策略限制（协议、域名、端口相同），导致了跨域问题的出现，请求无法携带cookie，导致session失效。此外，后端服务如果要搭建集群，还要解决单点session共享的问题。Redis满足数据共享、内存存储、键值对存储的要求，所以用redis来模拟。具体的做法是用雪花算法生成sessionID作为key，将验证码作为value保存在redis下，再将sessionId作为参数响应给前端，并且通过设置过期时间模拟Session过期失效的行为。

### 什么是雪花算法？

雪花算法是Twitter公司内部为分布式环境下生成唯一ID的一种算法解决方案，底层会帮助我们生成一个64比特位的long类型的Id。

![1663484469121.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1663484469121.png)

# 技术2：EasyExcel

## 描述

使用EasyExcel，实现个股统计数据的导出功能。

## 问题

### 为什么要用EasyExcel？

传统操作Excel大多都是利用Apach POI进行操作的，但是POI框架并不完善，使用过程非常繁琐且有较多的缺陷：

- 动态操作Excel非常繁琐，对于新手来说，很难在短时间内上手；
- 读写时需要占用较大的内存，当数据量大时容易发生内存溢出问题（OOM）；

基于上述原因，阿里开源出一款易于上手，且比较节省内存的Excel框架：EasyExcel。EasyExcel底层实现也是POI。

### EasyExcel怎么使用？

1. 导入依赖；
2. 调整与表格对应的实体类，使用@ExcelProperty注解来映射Excel列到Java字段，设置列明等等。‌也可以通过注解设置表格的样式。
    
    ```java
    @Data
    @NoArgsConstructor
    @AllArgsConstructor
    @Builder
    @HeadRowHeight(value = 35) // 表头行高
    @ContentRowHeight(value = 25) // 内容行高
    @ColumnWidth(value = 50) // 列宽
    public class User implements Serializable {
        @ExcelProperty(value = {"用户基本信息","用户名"},index = 1)
        @ExcelIgnore
        private String userName;
        @ExcelProperty(value = {"用户基本信息","年龄"},index = 2)
        private Integer age;
        @ExcelProperty(value = {"用户基本信息","地址"} ,index = 4)
        private String address;
        @ExcelProperty(value = {"用户基本信息","生日"},index = 3)
        //注意：日期格式注解由alibaba.excel提供
        @DateTimeFormat("yyyy/MM/dd HH:mm")
        private Date birthday;
    }
    ```
    
3. 使用EasyExcel的API读取或写入数据。
    
    ```sql
    EasyExcel.read(inputStream, YourModel.class, listener).sheet().doRead();
    EasyExcel.write(outputStream, YourModel.class).sheet("Sheet1").doWrite(dataList);
    ```
    

### EasyExcel最多可以导出多少行数据？

EasyExcel最多可以导出的行数据数量受到Excel版本和具体实现方式的限制。

### 如何导出百万级别的Excel？/使用EasyExcel导出数据导出时间过长怎么办？

- 使用EasyExcel可以实现流式写入，可以在写入数据的同时逐步将数据写入到文件中，而不是一次性将所有数据加载到内存中。这可以显著减少内存占用，提高导出效率。
- 分批导出。
    - **分页或分批查询**：将数据分成较小的批次进行导出，而不是一次性导出所有数据。这可以通过在代码中实现分页或分批查询的逻辑来完成。每次查询一定数量的数据（如每次10,000行），然后将其写入Excel文件中。
    - **多个Sheet或文件**：如果数据量非常大，可以考虑将数据分散到多个Sheet或文件中。每个Sheet或文件包含部分数据，最后可以将这些文件合并成一个Excel文件（如果需要）。
- 优化查询和数据处理。
    - **优化SQL查询**：确保用于导出数据的SQL查询是优化的，避免使用复杂的子查询、笛卡尔积等低效的查询方式。
    - **减少数据传输量**：在导出之前，可以对数据进行预处理，只导出必要的字段和记录，以减少数据传输量。
    - **优化代码逻辑**：对数据处理的代码进行优化，查看是否有不必要的计算和循环，提升代码性能。

# 技术3：RestTemplate、线程池和Xxl-job

## 描述

- 使用Xxl-job及RestTemplate实现股票数据的定时采集和解析。
- 使用线程池优化股票采集服务，提高采集的效率和线程的复用性。

## 问题

### 为什么要使用RestTemplate？

- 借助RestTemplate可以访问第三方的股票接口，拉取最新的股票数据流水。
- RestTemplate是Spring框架提供的一个非常轻量级的Http客户端，可以模拟浏览器的访问行为，获取接口数据。
- RestTemplate在Spring项目中的深度集成、简单易用、功能丰富以及良好的性能和稳定性。

### RestTemplate怎么使用？

- **引入依赖**：确保项目中引入了Spring Boot的Web依赖，因为RestTemplate通常与Web开发相关。
- **配置RestTemplate Bean**：在配置类中，通过`@Bean`注解声明一个RestTemplate的Bean，以便在整个应用程序中注入和使用。
- **使用RestTemplate**：在需要的地方（如Controller、Service等），通过自动装配（`@Autowired`）获取RestTemplate的实例，并调用其提供的方法来发送HTTP请求。
    
    ```java
    public void test(){
    		String url="http://localhost:6666/account/getHeader";
    		//设置请求头参数
    		HttpHeaders headers = new HttpHeaders();
        headers.add("userName","zhangsan");
    		//请求头填充到请求对象下
        HttpEntity<Map> entry = new HttpEntity<>(headers);
    		//发送请求
        ResponseEntity<String> result = restTemplate.exchange(url, HttpMethod.GET, entry, String.class);
        //获取响应头
        HttpHeaders headers = result.getHeaders();
        //响应状态码
        int statusCode = result.getStatusCodeValue();
        //响应数据
        String respData = result.getBody();
    }
    ```
    

### 从哪里获得的股票数据的采集接口？

目前市面上有一些正规的API金融接口，可为我们提供实时的股票金融数据，我们是从新浪财经提供的公共接口获取的数据，是免费的。

### 为什么使用多线程？

个股的数据很多，国内A股上市企业达3000+，在采集股票时，如果一次性批量获取某个时间点下股票的详情数据，显然单次请求的网络I/O开销大，磁盘I/O同样如此，这样会导致数据采集耗时过长！同时受限于第三方股票接口流量控制，也不会允许单次如此大的数据量的采集任务。

对此，我们将A股的编码集合拆分成若干组，然后再通过多线程分批次批量获取股票的实时信息。

### 使用的拒绝策略是什么？

CallerRunsPolicy，理由如下：

避免任务丢失：与直接丢弃任务的策略相比，`CallerRunsPolicy` 确保了每个任务都会被执行，只是可能不是以预期的并发方式。这对于那些不能容忍任务丢失的应用场景来说是非常重要的。

### 讲一下股票采集的流程？

通过Xxl-job设置了定时任务，在交易日每隔1分钟通过Http客户端restTemplate向第三方接口请求最新的股票数据（第三方接口有延迟，请求到重复数据？通过数据库的唯一性约束保证不重复），同时，由于个股请求量大，对个股的编号分组，通过多线程请求数据。

### 为什么要使用Xxl-job？

- 股票本身的数据是一系列的流水，所以，需要定时采集股票的最新数据。
- 常见的定时框架中，
    - Spring提供的Schedule功能比较单一；
    - Quartz开发起来比较复杂，不支持监控平台；
    - Xxl-job支持cron表达式，支持监控平台和任务警告等等，开发难度也相对简单。

### 如何使用Xxl-job？

- 在stock_job中引入核心依赖。
- 在application.yml中添加xxljob配置。
- 定义xxljob 核心配合bean，直接将xxl-job-executor-sample-springboot工程下的XxlJobConfig类复制过来即可。
- 定义任务处理器jobhandler。
    
    ```java
    @Component
    public class StockJob {
        @XxlJob("hema_job_test")
        public void jobTest(){
            System.out.println("jobTest run.....");
        }
    }
    ```
    
- 在可视化终端新增执行器，配置任务执行计划。
    
    ![1655748277837.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1655748277837.png)
    
- 启动任务。

### Xxl-job的原理？

1. 调度中心：一个单独的web服务，主要用来触发定时任务的执行。提供了一些页面操作，可以去管理定时任务的触发逻辑。调度中心依赖于数据库，所以下载工程之后需要执行提供的SQL脚本初始化数据库。调度中心也支持集群，但依赖的数据库必须是同一个，调度中心之间通过数据库通信。
2. 执行器：执行具体的任务逻辑。一个执行器中可以有多个任务。

调用中心是用来控制定时任务的触发逻辑，而执行器是具体执行任务的，这是一种任务和触发逻辑分离的设计思想，这种方式的好处就是使任务更加灵活，可以随时被调用，还可以被不同的调度规则触发。

1. 启动调度中心，创建调度线程，查询xxl_job_info表，找到下一次执行时间≤当前时间+5秒的任务。擦寻到任务后，将任务分成三类：超时5s以上的任务、超时不超过5s的任务、还没触发会在5s内触发的任务。第一类按照配置的过期策略执行，第二类立即执行，第三类放在时间轮里等待执行，然后更新xxl_job_info表的下一次触发时间。
2. 任务达到了触发条件，调度中心通过Http接口调用具体的执行器实例去触发任务。执行器接收到调度中心的请求，创建一个单独的线程JobThread去执行任务，之后的任务放到任务队列中，线程从中获取执行对应的JobHandler。
3. 任务处理完毕后，JobThread将结果发送到一个执行结果队列中。执行器在启动时会创建线程TriggerCallbackThread，会不停从队列中获取所有的执行结果，并批量发送给调度中心。调度中心根据任务结果做后续的处理，如修改执行状态、失败重试等。

### Xxl-job支持哪些任务执行方式？

- **Bean模式**：任务处理器是一个Spring Bean。执行器会找到该Bean，解析封装成MethodJobHandler对象，基于反射调用方法执行任务。
- Glue模式：动态修改任务执行的代码。
- Script模式：执行脚本。

### 什么是Cron表达式，项目中怎么定义？

- 分别从**秒、分、时、日、月、星期、年**七个时间维度来定义任务执行的周期。
- 国内大盘开盘周期是从周1到周5，每天上午的9:30至11:30和下午的1:00至3:00（节假日暂时不考虑），使用cron表达式不好一次性定义，所以我们可以将任务整体以半小时分段处理。
    - 前半小时表达式为：0 0-29 10,11,13,14 ? * 2-6
    - 后半小时表达式为：0 30-59 10,13,14 ? * 2-6
    
    | * | 匹配所有的值。如：*在分钟的字段域里表示 每分钟 |
    | --- | --- |
    | ? | 只在日期域和星期域中使用。它被用来指定“非明确的值” 不关心 |
    | - | 指定一个范围。如：“10-12”在小时域意味着“10点、11点、12点” |
    
    ![image-20220107121100108.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/image-20220107121100108.png)
    

# 技术4：RabbitMQ和CafﬁneCache

## 描述

使用RabbitMQ同步股票的最新数据，更新CafﬁneCache本地缓存。

## 问题

### 为什么使用MQ？

我们的大盘、股票等相关数据都是通过定时任务不断采集落库的，而对于大屏终端或用户也需要高频且实时获取股票最新数据，这会导致数据库过高的负载。

解决方案是：可在定时任务拉取股票数据时，将最新的数据信息通过mq同步到主业务工程进行缓存处理，这样就避免了多用户从数据库反复加载股票数据导致数据库负载过高的问题，同样也提高了大屏终端服务的吞吐量。

![1672843379691.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1672843379691.png)

### 为什么使用CaffineCache不用Redis？

- 使用CaffineCache本地缓存而非redis远程缓存，能提供更高效的响应速度，同时避免了与redis之间交换带来的网络I/O成本开销。
- CaffeineCache是一个Java库，与Java应用无缝集成，部署简单。它不需要额外的服务器或集群配置，降低了系统的复杂性和维护成本。

### 如何使用RabbitMQ？

1. 引入依赖：
    
    ```xml
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-amqp</artifactId>
    </dependency>
    ```
    
2. 在application.yml中配置rabbitmq。
    
    ```yaml
    spring:
      rabbitmq:
        host: 192.168.200.131 # rabbitMQ的ip地址
        port: 5672 # 端口
        username: itcast
        password: 123321
        virtual-host: /
    ```
    
3. 定义交换机与队列。
    
    ```java
    @Configuration
    public class MqConfig {
        /**
         * 重新定义消息序列化的方式，改为基于json格式序列化和反序列化
         * @return
         */
        @Bean
        public MessageConverter messageConverter(){
            return new Jackson2JsonMessageConverter();
        }
        /**
         * 国内大盘信息队列
         * @return
         */
        @Bean
        public Queue innerMarketQueue(){
            return new Queue("innerMarketQueue",true);
        }
        /**
         * 定义路由股票信息的交换机
         * @return
         */
        @Bean
        public TopicExchange innerMarketTopicExchange(){
            return new TopicExchange("stockExchange",true,false);
        }
        /**
         * 绑定队列到指定交换机
         * @return
         */
        @Bean
        public Binding bindingInnerMarketExchange(){
            return BindingBuilder.bind(innerMarketQueue()).to(innerMarketTopicExchange())
                    .with("inner.market");
        }
    }
    ```
    
4. 在获取最新数据的业务中增加向交换机发送信息。
    
    ```java
    @Override
    public void getInnerMarketInfo() {
    		//......
        //解析的数据批量插入数据库
        int count= stockMarketIndexInfoMapper.insertBatch(entities);
        log.info("当前插入了：{}行数据",count);
    		//通知后台终端刷新本地缓存，发送的日期数据是告知对方当前更新的股票数据所在时间点
        rabbitTemplate.convertAndSend("stockExchange","inner.market",new Date());
    }
    ```
    
5. 展示工程监听消息，刷新缓存。
    
    ```java
    @Component
    public class MqListener {
        @Autowired
        private Cache<String,Object> caffeineCache;
        @Autowired
        private StockService stockService;
        
        @RabbitListener(queues = "innerMarketQueue")
        public void acceptInnerMarketInfo(Date date)throws Exception{
            //获取时间毫秒差值
            long diffTime= DateTime.now().getMillis()-new DateTime(date).getMillis();
            //超过一分钟告警
            if (diffTime>60000) {
                log.error("采集国内大盘时间点：{},同步超时：{}ms",new DateTime(date).toString("yyyy-MM-dd HH:mm:ss"),diffTime);
            }
            //将缓存置为失效删除
            caffeineCache.invalidate("innerMarketInfosKey");
            //调用服务更新缓存
            stockService.getNewestInnerMarketInfos();
        }
    }
    ```
    

# 技术5：分库分表

## 问题

### 为什么要分库分表？

在项目中，股票数据会随着时间积累越来越多：

- 个股股票流水表：1500支重点股票1个月积累750w条数据（按年分库便于维护，按月分表）
- 股票主营业务：3000+，数量少，变化频率低，各个库都会用到（广播表）
- 大盘/外盘流水：1个月约60w条数据（按年分库便于维护，不分表）
- 系统表：sys_user / sys_log（单库默认数据源）

### 项目中如何分库分表？

![1649333428984.png](%E8%82%A1%E7%A5%A8%E6%8C%87%E6%95%B0%E7%B3%BB%E7%BB%9F%20a69d6df5abf048c8ba3604043ae536e7/1649333428984.png)

1. 为什么要按年分库：
    1. 便于将不常用的历史数据压缩归档；
    2. 便于后续数据库的线性扩容。
2. 为什么选择日期为分片键：
    1. 有利于数据库的维护和线性扩容。
    2. 股票查询时，很多按照日期作为条件，如果使用主键作为分片键，导致全节点查询，性能开销大。
3. 分片算法怎么实现？
    1. 分别自定义了分库、分表的算法，实现接口重写doSharding方法即可。
    2. doSharding方法通过给定的分片值找到对应的库/表或库/表的集合返回。
4. 注意事项：
    1. 条件查询时分片字段不要使用函数处理，否则分片算法失效，导致全节点查询。举例：select * from stock_rt_info where date_format(cur_time,‘%Y%m%d’)='20220910' ,函数会造成sharding的分片失效，导致全节点查询；
    2. 条件查询时尽量使用符合sharding分片条件的关键字(精确查询用=或in，范围查询用between)；
    3. sharding-jdbc对嵌套查询处理不友好。如果嵌套查询的话，那么最好子查询的条件只命中单张表；如果子查询的条件关联了多张表，那么交易分步骤拆分实现。

### 分库分表有哪些常见的框架实现？

- Sharding-jdbc（当当）
- Cobar（阿里巴巴）
- MyCAT（基于Cobar）
- Vitess（谷歌）
- ……

sharding-jdbc是一款轻量级Java框架，属于客户端产品不需要额外部署。几乎对所有关系型数据库都支持，对项目的侵入性很小。

### 简述下sharding-jdbc分库分表的执行原理？

1. SQL解析：会拦截SQL语句，并使用词法解析器和语法解析器对其进行解析，构建出语法树，通过遍历抽象语法树可以提炼出分片所需的上下文信息；
2. 路由计算：根据预先定义的分片键和分片算法，计算出需要路由到的数据库实例或表。
3. SQL改写与执行：根据路由结果改写原SQL并发送到对应的数据库实例和表中执行。
4. 结果归并：从各个数据节点获取的数据结果集会被组合成一个完整的结果集，并返回给应用。Sharding-JDBC负责处理这个过程中的合并逻辑，确保最终结果的准确性和完整性。

## 代码

### 配置文件

```xml
**# 第一步：配置shardingjdbc，一个库配置一个数据源**
# 数据源名称，多数据源以逗号分隔(datasource名称不要使用特殊符号)
spring.shardingsphere.datasource.names=ds-2021,ds-2022,df
# 配置三个数据源，省略
...

# **配置广播表**，如果有多个，以逗号间隔
spring.shardingsphere.sharding.broadcast-tables=stock_business
# 配置**默认数据源**
spring.shardingsphere.sharding.default-data-source-name=df

# **第二步：配置板块表以及大盘外盘表的数据节点信息（只分库不分表）**
spring.shardingsphere.sharding.tables.stock_block_rt_info.actual-data-nodes=ds-${2021..2022}.stock_block_rt_info
...省略其他两个表的配置

# 提取公共数据库分片算法配置类
common.algorithm4db=com.itheima.stock.sharding.CommonShardingAlgorithm4Db

# 配置数据库的分片算法
# 分片列名称
spring.shardingsphere.sharding.tables.stock_block_rt_info.database-strategy.standard.sharding-column=cur_time
# 精确分片算法类名称，用于 = 和 IN。该类需实现 PreciseShardingAlgorithm 接口并提供无参数的构造器
spring.shardingsphere.sharding.tables.stock_block_rt_info.database-strategy.standard.precise-algorithm-class-name=${common.algorithm4db}
# 范围分片算法类名称，用于 BETWEEN，可选。该类需实现 RangeShardingAlgorithm 接口并提供无参数的构造器
spring.shardingsphere.sharding.tables.stock_block_rt_info.database-strategy.standard.range-algorithm-class-name=${common.algorithm4db}
...省略其他两个表的配置

# **第三步：配置个股的数据节点（分库+分表）**
# 配置股票流水节点信息
spring.shardingsphere.sharding.tables.stock_rt_info.actual-data-nodes=ds-2021.stock_rt_info_${202101..202112},ds-2022.stock_rt_info_${202201..202212}

# 抽取公共配置类变量
common.algorithm4StockRtInfoTable=com.itheima.stock.sharding.ShardingAlgorithm4StockRtInfoTable

# 配置股票流水库分片策略
spring.shardingsphere.sharding.tables.stock_rt_info.database-strategy.standard.sharding-column=cur_time
# 精确分片算法类名称，用于 = 和 IN。该类需实现 PreciseShardingAlgorithm 接口并提供无参数的构造器
spring.shardingsphere.sharding.tables.stock_rt_info.database-strategy.standard.precise-algorithm-class-name=${common.algorithm4db}
# 范围分片算法类名称，用于 BETWEEN，可选。该类需实现 RangeShardingAlgorithm 接口并提供无参数的构造器
spring.shardingsphere.sharding.tables.stock_rt_info.database-strategy.standard.range-algorithm-class-name=${common.algorithm4db}

# 配置表的分片算法
# 配置股票流水表的分片算法
spring.shardingsphere.sharding.tables.stock_rt_info.table-strategy.standard.sharding-column=cur_time
# 精确分片算法类名称，用于 = 和 IN。该类需实现 PreciseShardingAlgorithm 接口并提供无参数的构造器
spring.shardingsphere.sharding.tables.stock_rt_info.table-strategy.standard.precise-algorithm-class-name=${common.algorithm4StockRtInfoTable}
# 范围分片算法类名称，用于 BETWEEN，可选。该类需实现 RangeShardingAlgorithm 接口并提供无参数的构造器
spring.shardingsphere.sharding.tables.stock_rt_info.table-strategy.standard.range-algorithm-class-name=${common.algorithm4StockRtInfoTable}
```

# 其他问题

### 项目的难点在哪里？项目有什么问题？怎么解决的？

可回答的点：

1. 线程池优化；
2. MQ+Caffine优化；
3. 分库分表。