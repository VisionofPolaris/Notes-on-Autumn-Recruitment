# 操作系统

# 硬件

## 冯诺依曼体系

- 中央处理器：控制器、运算器、寄存器（通用寄存器-运算数据、程序计数器-下一条指令地址、指令寄存器-正在执行的指令）；
- 内存：存储器；
- 输入设备、输出设备；
- 总线（地址总线、控制总线、数据总线）。
1. 32位CPU一次能操作32根地址总线，32根地址总线表示的地址总量是2^32，即4G。每个字节对应一个地址，所以32位CPU最大只能操作4GB内存。
2. 64位CPU相对与32位CPU：
    1. 能一次计算超过32位的数字，但只有在数字超过32位时优势才能体现出来；
    2. 能够寻址的物理空间更大，2^48。
3. CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 **CPU 的指令周期**。
4. 程序的CPU执行时间=指令数×每条指令的平均时钟周期（CPI）×时钟周期时间。

### 中央处理器

![CPU架构.webp](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20e99b5add18e74f91a7ea6dfb9e7cb271/CPU%25E6%259E%25B6%25E6%259E%2584.webp)

### 存储器

![存储器的层次关系图.webp](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20e99b5add18e74f91a7ea6dfb9e7cb271/%25E5%25AD%2598%25E5%2582%25A8%25E5%2599%25A8%25E7%259A%2584%25E5%25B1%2582%25E6%25AC%25A1%25E5%2585%25B3%25E7%25B3%25BB%25E5%259B%25BE.webp)

1. CPU Cache数据的写入：
    1. 如果数据已在CPU Cache中，则将相关的数据块设为dirty；
    2. 如果数据不在CPU Cache中，且数据块里有数据为脏，则将块中数据写回内存，再读入当前需要写入的数据，写入后标记为脏。
    3. 如果数据不在CPU Cache中，且数据块里没有数据为脏，读入当前需要写入的数据，写入后标记为脏。
2. 缓存一致性：L1/L2是各个CPU核心独自拥有，存在多个核心的缓存一致性问题，通过基于总线嗅探的MESI协议解决。
    1. 总线嗅探：每个 CPU 核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的Cache 里面；
    2. MESI协议：已修改、独占、共享、已失效这四个状态的英文缩写的组合，Cache Line在四个状态中流转。

## 中断

### 什么是中断？

中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度的地影响。

- 外围硬件发给CPU或者内存的异步信号就是硬中断信号。
- 由软件本身发给操作系统内核的中断信号，称之为软中断。通常是由硬中断处理程序或进程调度程序对操作系统内核的中断，也就是我们常说的系统调用（System Call）了。

关于软中断可以由硬中断发起：

 Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段：

- **上半部直接处理硬件请求，也就是硬中断**，主要是负责耗时短的工作，特点是快速执行；
- **下半部是由内核触发，也就说软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行。

硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个 CPU 都对应一个软中断内核线程。

# 基础

### 什么是操作系统？

- 操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。
- 操作系统屏蔽了硬件的复杂性。
- 操作系统的内核是操作系统的核心部分，负责系统的内存管理，文件系统管理，应用程序管理，硬件设备管理等等。

### 什么是用户态和系统态？

- 内存被操作系统划分为用户空间和内核空间，用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。
- 根据资源访问的特点，把进程在OS上的运行分两个级别：用户态运行的进程可以直接读取用户程序的数据；内核态运行的程序几乎可以访问计算机的任何资源，不受限制。

### 什么是系统调用？

我们运行的程序基本运行在用户态，如果有与系统态级别的资源有关的操作（文件管理、内存管理等），都必须通过系统调用的方式向OS提出服务请求，由操作系统代为完成。

- 设备管理：设备的请求、释放和启动等；
- 文件管理：文件的读、写、创建和删除等；
- 进程控制：进程的创建、撤销、阻塞和唤醒等；
- 进程通信：进程之间信号的传递；
- 内存管理：内存的分配、回收等。

# 内存管理

### 操作系统的内存管理主要的工作？

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。

### 内存管理机制有哪些？

- 连续分配管理方式：为一个用户程序分配一个连续的内存空间。
    - 块式管理：古早方式。将内存分为几个固定大小的块，程序需要内存就分配一块，如果程序很小会有很大的内部碎片。
- 非连续分配管理方式：允许一个程序使用的内存分布在离散的内存中。
    - 段式管理：将主存分为一段段的，并且具有实际意义，例如有主程序段MAIN、子程序段X、数据段D及栈段S等。通过段表对应逻辑地址和物理地址。段式管理会有外部碎片。
    - 页式管理：页式管理将主存分为大小相等的一页一页的形式，一般比较小，Linux里是4KB。相对于块式管理减少了内部碎片，并且在加载程序的时候只需要将需要的页加载进内存，有效提高了内存的利用率。通过页表对应逻辑地址和物理地址。
    - 段页式管理：结合了段式管理和页式管理的优点，先将主存分成若干段，每个段又分为若干页。

### 快表和多级页表？

在分页管理中，涉及两个重要的问题：

- 虚拟地址到物理地址的转换要快；
- 虚拟地址空间大，页表也大的问题。
1. 快表提高了虚拟地址到物理地址转换的速度，相当于页表的Cache，在读写主存数据时，只需要一次访问高速缓存，一次访问主存，加速查找并提高指令执行的速度。地址转换流程：
    1. 根据虚拟地址中的页号查找快表；
    2. 如果该页在快表中，直接从快表中获取物理地址；
    3. 如果该页不在快表中，就访问内存中的页表，再从页表中获取物理地址，同时将页表中的该映射表项添加到快表中；
    4. 如果快表填满，又要登记新页，就按照一定的淘汰策略淘汰掉页表中的一个页。
2. 多级页表是为了避免将全部的页表都放在内存中导致占用过多的空间，将页表分成了一级页表、二级页表等等，二级等页表只需要在需要的时候再加载到内存中。但查询多级页表会更耗时，属于时间换空间的场景。

### 分页与分段管理的共同点和区别？

- 共同点
    - 设计目的相同，为了提高内存的利用率，减少碎片；
    - 都是离散分配内存的方式，每个页和段中的内存是连续的。
- 不同点
    - 页的大小是固定的，由操作系统决定。段的大小是不固定的，由当前运行的程序决定；
    - 分页是为了满足操作系统的内存管理需求，而段是逻辑信息的单位，在程序中可以体现为代码段、数据段，能满足用户的需要。

### 解释一下虚拟地址和物理地址。

物理地址是指真实内存中的地址。多个程序如果直接使用物理地址可能会导致多个程序之间的干扰和冲突，而虚拟地址隐藏了底层复杂的物理地址管理细节，由内存管理单元负责地址的转换与解析，为每个程序提供了独立的地址空间。使用虚拟地址：

- 可以通过一系列连续的地址访问物理内存中不相邻的区域。
- 可以通过虚拟地址访问大于可用物理内存的内存区，数据和代码会根据需要在物理内存和磁盘之间移动。
- 进程隔离，不同进程使用的虚拟地址彼此隔离，避免冲突。

### 什么是虚拟内存？

- 虚拟内存是子计算机系统内存管理的一种技术，定义了一个连续的地址空间，并把内存扩展到硬盘空间。
    - 虚拟内存可以让程序拥有超过系统物理内存大小的可用内存空间。
    - 虚拟内存为每个进程提供了一个一致的、私有的地址空间，让每个进程产生了一种自己在独享主存的错觉。

### 虚拟内存为什么可以只装入部分程序就可以运行？

因为程序运行具有局部性原理，在某个较短的时间内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。

- 时间局部性：程序中某条指令或数据在执行或访问后，不久可能再次被访问；
- 空间局部性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问。

虚拟内存技术实际上就是建立了“内存-外存”的两级存储器结构，利用局部性原理实现高速缓存。

### 虚拟内存的实现？

通过离散分配的内存管理方式实现，主要有以下三种方式：

- 请求分页存储管理：在分页管理之上增加了请求调页和页面置换功能。
- 请求分段存储管理：在分段管理之上增加了请求调段和分段置换功能。
- 请求段页式存储管理。

无论哪一种方式，都需要：

- 一定容量的内存和外存；
- 缺页中断：如果需要执行的指令或数据不在内存（缺页或缺段），则由处理器通知操作系统将相应的页面和段调入到内存；
- 虚拟地址空间：实现逻辑地址到物理地址的变换。

### 页面置换算法有哪些？

- OPT（Optimal）最佳页面置换算法：淘汰的页面是以后永不使用的或是在最长时间内不再被访问的页面。（无法实现）
- FIFO先进先出页面置换算法：淘汰最先进入内存的页面。
- LRU（Least Recently Used）最近最久未使用页面置换算法：赋予每个页面一个访问字段，记录自上次访问以来所经历的时间，选择现有页面中最久没被访问的页面给予淘汰。
- LFU（Least Frequently Used）最少使用页面置换算法：选择在之前时期使用最少的页面作为淘汰页。

# 进程管理

## 进程

### 进程有哪些状态？

![10-进程七中状态.webp](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20e99b5add18e74f91a7ea6dfb9e7cb271/10-%25E8%25BF%259B%25E7%25A8%258B%25E4%25B8%2583%25E4%25B8%25AD%25E7%258A%25B6%25E6%2580%2581.webp)

- 阻塞状态：该进程等待某一事件的发生，即使给他CPU的控制权，也无法运行；
- 挂起状态：进程没有占用实际的物理内存空间，而是换出到了硬盘。

### 进程的控制

1. **创建**：1）申请空白的PCB，并向 PCB 中填写一些控制和管理进程的信息，2）为该进程分配运行时所必需的资源，3）将 PCB 插入到就绪队列，等待被调度运行。
2. **终止**：1）查找终止进程的PCB，2）如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程，3）如果其还有子进程，则应将该进程的子进程交给 1 号进程接管，4）将该进程所拥有的全部资源都归还给操作系统，5）将其从 PCB 所在队列中删除。
3. **阻塞**：1）找到将要被阻塞进程标识号对应的 PCB；2）如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；3）将该 PCB 插入到阻塞队列中去。
4. **唤醒**：1）在该事件的阻塞队列中找到相应进程的 PCB；2）将其从阻塞队列中移出，并置其状态为就绪状态；3）把该 PCB 插入到就绪队列中，等待调度程序调度。

### 发生进程切换的场景有哪些？

- 进程运行的时间片耗尽，从就绪队列选择另一个进程；
- 系统资源不足，进程被挂起，系统调度其他进程；
- 进程通过sleep()主动挂起；
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

## 线程

### 线程的优缺点？

- 优点：并发执行、共享进程资源减少开销。
- 缺点：一个线程崩溃，导致进程中所有线程崩溃（C/C++）。
    
    > 线程的地址空间是共享的，某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个**进程崩溃**。进程的崩溃通过信号机制完成，JVM自定义了信号处理函数，做了额外的处理以让 JVM 不崩溃。
    > 

### 进程与线程的比较？

- 进程是资源分配的基本单位，线程是CPU调度的基本单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程能减少并发执行的时间和空间开销。
    - 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
    - 线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
    - 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
    - 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了。

### 线程的上下文切换？

这还得看线程是不是属于同一个进程：

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
- **当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。**

所以，线程的上下文切换相比进程，开销要小很多。

### 线程的实现方式？

- **用户线程**：用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。用户级线程的模型为多对一关系，多个用户线程对应同一个内核线程。
    - 线程的切换不需要进入内核态，节省切换的开销；用户级线程的实现与操作系统无关，对线程的管理属于用户程序的一部分；
    - 当线程执行系统调用时，进程内的所有线程都被阻塞；CPU的调度仍然是以进程为单位的，不能发挥多处理机的优势。
- **内核线程**：内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。内核线程的模型，也就类似前面提到的**一对一**的关系，即一个用户线程对应一个内核线程。
    - 内核能同时调度同一个进程中的多个线程并行执行；
    - 同一进程内的线程切换需要转到核心态下，系统开销大。
- **轻量级进程**：轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。在LAW之上可以使用用户线程，可以是1:1、N:1、M:N的关系。

## 调度

### 调度的时机？

在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。

1. 当进程从运行状态转到阻塞状态；（非抢占式调度）
2. 当进程从运行状态转到就绪状态；（抢占式调度）
3. 当进程从阻塞状态转到就绪状态；（非抢占式调度）
4. 当进程从运行状态转到终止状态。（抢占式调度）
- 抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。
- 抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。

### 进程调度算法有哪些？

1. 先来先服务调度算法（First Come First Serve, FCFS）：每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。（对长作业有利，短作业可能等待时间很长）
2. 最短作业优先调度算法（Shortest Job First, SJF）：同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。（对长作业不利，可能导致饥饿）
3. 高响应比优先调度算法 （Highest Response Ratio Next, HRRN）：主要是权衡了短作业和长作业。每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行。（现实中用不了，要求服务时间不可预估）
    
    $$
    优先权=\frac{等待时间+要求服务时间}{要求服务时间}
    $$
    
4. 时间片轮转调度算法（Round Robin, RR）：每个进程被分配一个时间段，称为时间片（*Quantum*），即允许该进程在该时间段中运行。
5. 最高优先级调度算法（Highest Priority First，HPF）：调度程序能从就绪队列中选择最高优先级的进程进行运行，进程的优先级可以分为，静态优先级和动态优先级：
    1. 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
    2. 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。
    
    该算法也有两种处理优先级高的方法，非抢占式和抢占式：
    
    1. 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
    2. 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。
6. 多级反馈队列调度算法（Multilevel Feedback Queue）：「时间片轮转算法」和「最高优先级算法」的综合和发展。
    
    ![28-多级队列.webp](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20e99b5add18e74f91a7ea6dfb9e7cb271/28-%25E5%25A4%259A%25E7%25BA%25A7%25E9%2598%259F%25E5%2588%2597.webp)
    
    - 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
    - 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；
    - 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
    - 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
    - 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行。

## 进程通信

### 进程通信的方式有哪些？

### 管道

- 管道的本质是内核中的一串缓存，遵循先进先出的原则。
- 管道分为
    - 匿名管道：命令`ps auxf | grep mysql` 中的|就是匿名管道，通信范围是存在父子关系的进程。
    - 命名管道：通过`mkfifo`创建，以文件的方式存在，可以在不相关的进程间相互通信。
- 管道的通信方式效率低，不适合进程间频繁交换数据。

### 消息队列

- 消息队列是保存在内核中的消息链表，消息体可以是用户自定义的数据类型。A进程将数据放在对应的消息队列之后可以正常返回，B进程需要数据的时候再去读取。
- 消息队列不足的地方：
    - 通信不及时，存在用户态和内核态之间的数据拷贝开销；
    - 不适合比较大数据的传输，内核中消息体和全部消息的总长度有上限。

### 共享内存

- **拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

### 信号量

- 信号量是一个计数器，可以保护共享资源，不仅可以实现访问的互斥性，还可以实现进程间的同步。

### 信号

- **对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**
- 信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程。

### Socket

- Socket不仅可以在同主机进程间通信，也可以跨网络与不同主机上的进程通信。
- 可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

## 死锁

### 什么是死锁？

当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成**两个线程都在等待对方释放锁**，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。

### 死锁的四个必要条件？

- 互斥条件：多个线程不能同时使用同一个资源；
- 持有并等待条件：线程在等待资源的同时不会释放已有的资源；
- 不可剥夺条件：线程已经持有了资源，在自己使用完之前不能被其他线程获取；
- 循环等待条件：两个线程获取资源的顺序构成了环形链。

### 怎么排查死锁？

可以使用jstack工具，是jdk自带的线程堆分析工具。

### 写一个死锁的代码？

```java
class DeadLock {
    private static Object src1 = new Object();
    private static Object src2 = new Object();

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (src1) {
                System.out.println("线程1获取资源1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("线程1 准备 获取资源2");
                synchronized (src2) {
                    System.out.println("线程1获取资源2");
                }
            }
        }).start();

        new Thread(() -> {
            synchronized (src2) {
                System.out.println("线程2获取资源2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("线程2 准备 获取资源1");
                synchronized (src1) {
                    System.out.println("线程2获取资源1");
                }
            }
        }).start();
    }
}
```

### 如何解决死锁？

1. 死锁的预防：
    1. 静态分配策略：静态分配策略可以破坏死锁产生的第二个条件（占有并等待）。一个进程必须在执行前就申请到它所需要的全部资源，并且知道它所要的资源都得到满足之后才开始执行。
    2. 层次分配策略：层次分配策略破坏了产生死锁的第四个条件(循环等待)。在层次分配策略下，所有的资源被分成了多个层次，一个进程得到某一次的一个资源后，它只能再申请较高一层的资源；当一个进程要释放某层的一个资源时，必须先释放所占用的较高层的资源，按这种策略，是不可能出现循环等待链的。
    
    资源利用率低
    
2. 死锁的避免：将系统的状态分为 **安全状态** 和 **不安全状态** ，每当在为申请者分配资源前先测试系统状态，若把系统资源分配给申请者会产生死锁，则拒绝分配，否则接受申请，并为它分配资源。
    1. **银行家算法** 通过先 **试探** 分配给该进程资源，然后通过 **安全性算法** 判断分配后系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待，若能够进入到安全的状态，则就 **真的分配资源给该进程**。
    
    花费较多时间检测资源使用以及安全性检查
    
3. 死锁的检测：法对资源的分配不加以任何限制，也不采取死锁避免措施，但系统 **定时地运行一个 “死锁检测”** 的程序，判断系统内是否出现死锁，如果检测到系统发生了死锁，再采取措施去解除它。
    1. 如果进程-资源分配图中无环路，则此时系统没有发生死锁；
    2. 如果进程-资源分配图中有环路，且每个资源类仅有一个资源，则系统中已经发生了死锁；
    3. 如果进程-资源分配图中有环路，且涉及到的资源类有多个资源，此时系统未必会发生死锁。如果能在进程-资源分配图中找出一个**既不阻塞又非独立的进程**，该进程能够在有限的时间内归还占有的资源，也就是把边给消除掉了，重复此过程，直到能在有限的时间内**消除所有的边**，则不会发生死锁，否则会发生死锁。
4. 死锁的解除：
    1. **立即结束所有进程的执行，重新启动操作系统**：这种方法简单，但以前所在的工作全部作废，损失很大。
    2. **撤销涉及死锁的所有进程，解除死锁后继续运行**：这种方法能彻底打破**死锁的循环等待**条件，但将付出很大代价，例如有些进程可能已经计算了很长时间，由于被撤销而使产生的部分结果也被消除了，再重新执行时还要再次进行计算。
    3. **逐个撤销涉及死锁的进程，回收其资源直至死锁解除。**
    4. **抢占资源**：从涉及死锁的一个或几个进程中抢占资源，把夺得的资源再分配给涉及死锁的进程直至死锁解除。